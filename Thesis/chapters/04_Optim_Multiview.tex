% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Stereo Rendering Optimization - Effort reduction}
This second chapter of optimization approaches targets the efficiency of rendering processes on the graphics chip itself. These approaches have little to no impact on CPU performance and tend to exploit and scale mostly with GPU power. 

\section{Multiview stereo rendering}
\subsection{Theory}
When rendering a stereo image using the naive method of simply going through the entire rendering pipeline once for each viewport, potentially a lot of computation is done twice with little or no change in data or parameters. 
With the [TODO: illustration of general graphics pipeline] in mind, it's clear that for example the vertex stage will see very little change in output as geometry and index buffers are largely the same between multiple stereo viewport passes with only minor shifts in the view matrices. Similarly, the geometry stage is commonly not dependent on specific eye data and as such would be a waste to process with the same data twice. Once the rasterizer stage of the pipeline is reached, the situation changes as stereo separation means the two images have notably different content and work from one can not realistically be recycled in the other. \\

An optimization exploiting this is called multiview stereo rendering, and very quickly surfaced as an idea after the introduction of the Nvidia Geforce 8 and ATi Radeon HD 2000 series in 2006 brought unified shader architectures to the market [SRC: arch whitepaper]. Prior architectures relied on separate vertex and pixel shader units with relatively fixed capabilities and few ways to share data. Fully programmable shader units then allowed more customizable and efficient pipeline usage necessary for multiview to show any benefit. 
The lack of mainstream stereoscopic systems prohibited the feature from becoming more important until the official introduction of multiview extensions to graphics APIs like OpenGL (\codeword{GL_OVR_multiview}) and Vulkan (\codeword{VK_KHR_Multiview}, previously \codeword{_KHX} and \codeword{_NV}). 
The same resurgence saw the idea expanded and further optimized and - in more recent vendor specific terms - Nvidia calling it Single Pass Stereo, Simultaneous Multi-Projection and Multi-View rendering and AMD calling it LiquidVR multiview [SRC: dev page for each]. The idea behind all these terms is the same, albeit with detail differences between the different flavors. \\

The core concept of multiview rendering is to submit all draw commands for a stereoscopic frame in one call instead of two separate passes, which can cut down CPU render and transfer time depending on the type and amount of data pushed to the GPU. Expensive synchronization barriers are essentially halved and all necessary writes are performed in a single go. 
As an addition, \textit{hardware} multiview rendering is to only perform those pipeline stages multiple times that actually produce notably different data for each eye, such as the rasterizer and pixel shader stages, while only running the earlier stages with little changes once. The data from stages run only once can then be reused by the multiply run stages with very little extra cost. This expanded technique improves pipeline efficiency and will scale heavily depending on workload. For fragment-heavy applications the benefit will be limited while high vertex or geometry loads tend to scale more optimally. Hardware acceleration requires additional registers and pipeline shortcuts in the chip itself though, which constraints it to more modern GPU architectures built with it in mind [SRC: Nv GDC 2015, etc]. Nvidia could be considered the main progress drivers for this, having pushed the technology from parallel geometry projection in Maxwell's Multi-Projection Acceleration to Pascal's SMP which adds lens-matched shading to better approximate the lens shape and finally to Turing's Multi-View with a doubling of available views and positional independence to support state of the art HMDs with canted displays [SRC: T MV dev entry]. \\

[TODO: illustration] \\

The small tradeoff then is that all relevant view data for each viewport has to be handed to the pipeline at once, creating a little higher memory overhead. Additionally certain buffers such as geometry and indices for the vertex stage need to be uniform across all viewports and can't be altered for each eye as they are processed in a single pass. [TODO: is there any warping happening? -> very slight artifacts possible] \\

Going by the user-maintained Vulkan Hardware Database [SRC: vulkan.gpuinfo.org/listreports.php?extensionfeature=multiview]
The major GPU vendors specify multiview support in their architectures as follows: 
\begin{itemize}
\item Nvidia: hardware multiview from the Maxwell generation and newer, software support from Kepler onward
\item AMD: software support from Graphics Core Next 1.0 onward [TODO: hw support?]
\item Intel: software support begins with Generation 9.0 (Skylake/Apollo Lake GT) onward under Windows, Generation 7.0 (Ivy Bridge GT) onward under Linux [TODO: hw support?]
\item Qualcomm: software support from Adreno 500 onward
\item ARM: software support from Bifrost onward, limited support on Midgard
\item Imagination: software support from Rogue onward
\end{itemize}
Note here while support of the desktop parts is solid and stable, the ARM-based mobile chipsets often have incomplete or unstable drivers [SRC: reports?]. \\
For all submitted devices (892 at the time of writing) the database shows support coverage of 54\% on Windows systems, 69\% on Linux systems and only 23\% on Android. This statistic may not be very reliable, however, as an undetermined portion of the submissions contains incomplete or flawed information such as drivers versioned as 0.0.0 or API versions reported as 0.0.1. 

\subsection{Estimated impact}
Impact of this extension is highly dependent on the specific workload, the used graphics hardware and renderer structure. \\

[TODO: AMD LiquidVR numbers, Anand SMP tests, Nv MV dev blog]

\subsection{Implementation specifics}
In Vulkan specifically, multiview is enabled through the \codeword{VK_KHR_multiview} extension. This extension's availability on the target hardware can be queried and if available, the individual hardware-dependent implementation is abstracted by Vulkan. \\
In the Tachyon implementation of multiview, the following changes to the render loop are introduced: 
\begin{itemize}
\item The VR render target adds \codeword{VK_KHR_GET_PHYSICAL_DEVICE_PROPERTIES_2} to the required instance extensions and \codeword{VK_KHR_MULTIVIEW} to the required device extensions during Vulkan instance and device creation at startup
\item the previously separate per-eye VR render passes are merged into a single render pass
\item this VR render pass incorporates the multiview pNext extension using a view mask and correlation mask of 0x11, with each of those bits representing one of the eyes
\item the Frustum Culling pass combines the two frustum checks with an early accept and outputs a merged set of draw call information
\item the second command buffer recording - previously intended for the second eye - in \codeword{OpenVR::RecordCommandBuffers} is cut out as multiview render passes can only take a single unified set of command buffers
\item the underlying GLSL shader is modified to pick camera parameters based not only on a given camera index, but also the implicit \codeword{gl_viewIndex} as Vulkan multiview uses this integer to index the current viewport
\end{itemize}
The VR render target's framebuffer, color attachment and depth attachment are already set up as dual-layered buffers which makes them readily compatible with multiview render passes. With these changes, the Tachyon renderer is fully switched over to single pass stereo rendering. 